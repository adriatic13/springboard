Adrian Marinovich 
Springboard Data Science Career Track 
Capstone Project #1 Ideas


1. Classification of emotion using the Ryerson RAVDESS video database: Machine learning techniques will be used to classify 6 'culturally universal' primary emotions (happy, sad, angry, fearful, surprise, disgust) using data derived from video clips of facial expressions performed by actors during speech and song in a structured setting, for which validated ground truth emotional expression has been specified. There may be a wide range of clients interested in the emotional classification from video of human facial expression, including robotics applications to allow for more emotionally responsive human-robot interactions. Ways the Springboard curriculum may be followed in the development of this project include:
   Data wrangling - Conversion of video clips to machine-readable data format
                  - Breakdown of video data to training, validation and test sets
   Exploratory data analysis - Emotional classification on representative static images 
                               using segmentation of head, eyes and eyebrows and mouth, and using dynamic video for movement tracking of these and other segments
   Machine learning - Emotional classification using neural networks, both on static 
                      images and dynamic video

   Additional work may extend to analysis of accompanying audio, and to differentiation between speech and song.
   
Reference:
Livingstone SR, Russo FA (2018) The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic,multimodal set of facial and vocal expressions in
North American English. PLoS ONE 13(5):e0196391. https://doi.org/10.1371/journal.pone.0196391

2. Classification of seagoing vessels based on their underwater acoustic signature:
This would be accomplished by correlation of underwater acoustic data at fixed ocean locations to Universal Shipborne Automatic Identification System (AIS) tracking of vessels passing in sea lanes near those locations. This classification method may be useful to clients in government and the maritime industry by providing an alternative to AIS tracking. The aim is to classify vessels across a range of characteristics, including vessel size, type (cargo, tanker, fishing, etc.), propulsion characteristics, and possibly individual vessel identity. Vessel location, direction and speed may also be assessed. Acoustic data are freely available from the Ocean Observatories Initiative, and AIS tracking is available via sites such as aishub.net and shipplotter.com.

3. Kaggle competition - "Airbus Ship Detection Challenge": The challenge is "to build a model that detects all ships in satellite images as quickly as possible." To do this, the model must "locate ships in images, and put an aligned bounding box segment around the ships you locate. Many images do not contain ships, and those that do may contain multiple ships. Ships within and across images may differ in size (sometimes significantly) and be located in open sea, at docks, marinas, etc." Clients for such a model include environmental protection agencies, defense and law enforcement agencies and insurance companies seeking to have a detailed view of worldwide ship traffic.

4. Open Conductor: Using an OpenMV camera on a MicroPython board to detect and classify hand, baton and body gestures to output structured music based on modeling from actual conductor videos. This project would use a cheap and open-source camera and microcontroller setup utilizing a bare-bones program to allow users to create music using their hand, baton and body motions to control MIDI output. This would be of interest to those developing natural user interfaces for a variety of applications, as it could be modified to output other instructions for control purposes as needed.
