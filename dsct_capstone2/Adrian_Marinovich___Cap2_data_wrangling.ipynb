{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adrian Marinovich\n",
    "# Springboard - Data Science Career Track \n",
    "# Capstone Project #2\n",
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from scipy.stats import reciprocal, uniform\n",
    "from scipy.misc import imsave\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# for reproducibility:\n",
    "np.random.seed(41)\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(51)\n",
    "random.seed(61)\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "    \n",
    "from keras.models import model_from_yaml\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.svm import SVC \n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# setup plots\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (adapted from:\n",
    "#    https://github.com/harvitronix/five-video-classification-methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain data\n",
    "#\n",
    "# bash command line in data folder:\n",
    "# $ wget http://crcv.ucf.edu/data/UCF101/UCF101.rar\n",
    "# $ unrar e UCF101.rar\n",
    "# $ mkdir train && mkdir test && mkdir sequences && mkdir checkpoints\n",
    "#\n",
    "# Get following 2 files from:\n",
    "#     https://github.com/harvitronix/five-video-classification-methods/tree/master/data/ucfTrainTestlist\n",
    "#\n",
    "#   trainlist01.txt\n",
    "#   testlist01.txt\n",
    "#\n",
    "#   ...and put in /home/adrian01/ucf101_lists\n",
    "#"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# DONE - DO NOT RUN!\n",
    "# (adapted from:\n",
    "#   https://github.com/harvitronix/five-video-classification-methods/blob/master/data/1_move_files.py )\n",
    "\n",
    "\"\"\"\n",
    "After extracting the RAR, we run this to move all the files into\n",
    "the appropriate train/test folders.\n",
    "Should only run this file once!\n",
    "\"\"\"\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "def get_train_test_lists(version='01'):\n",
    "    \"\"\"\n",
    "    Using one of the train/test files (01, 02, or 03), get the filename\n",
    "    breakdowns we'll later use to move everything.\n",
    "    \"\"\"\n",
    "    # Get our files based on version.\n",
    "    \n",
    "    os.chdir(\"/home/adrian01/ucf101_lists\")\n",
    "\n",
    "    test_file = os.path.join('/home/adrian01/ucf_lists/testlist01.txt')\n",
    "    train_file = os.path.join('/home/adrian01/ucf_lists/trainlist01.txt')\n",
    "\n",
    "    os.chdir(\"/home/adrian01/ucf101\")\n",
    "    \n",
    "    # Build the test list.\n",
    "    with open(test_file) as fin:\n",
    "        test_list = [row.strip() for row in list(fin)]\n",
    "\n",
    "    # Build the train list. Extra step to remove the class index.\n",
    "    with open(train_file) as fin:\n",
    "        train_list = [row.strip() for row in list(fin)]\n",
    "        train_list = [row.split(' ')[0] for row in train_list]\n",
    "\n",
    "    # Set the groups in a dictionary.\n",
    "    file_groups = {\n",
    "        'train': train_list,\n",
    "        'test': test_list\n",
    "    }\n",
    "\n",
    "    return file_groups\n",
    "\n",
    "def move_files(file_groups):\n",
    "    \"\"\"This assumes all of our files are currently in _this_ directory.\n",
    "    So move them to the appropriate spot. Only needs to happen once.\n",
    "    \"\"\"\n",
    "    \n",
    "    os.chdir(\"/home/adrian01/ucf101\")\n",
    "    \n",
    "    # Do each of our groups.\n",
    "    for group, videos in file_groups.items():\n",
    "\n",
    "        # Do each of our videos.\n",
    "        for video in videos:\n",
    "\n",
    "            # Get the parts.\n",
    "            parts = video.split(os.path.sep)\n",
    "            classname = parts[0]\n",
    "            filename = parts[1]\n",
    "\n",
    "            # Check if this class exists.\n",
    "            if not os.path.exists(os.path.join(group, classname)):\n",
    "                print(\"Creating folder for %s/%s\" % (group, classname))\n",
    "                os.makedirs(os.path.join(group, classname))\n",
    "\n",
    "            # Check if we have already moved this file, or at least that it\n",
    "            # exists to move.\n",
    "            if not os.path.exists(filename):\n",
    "                print(\"Can't find %s to move. Skipping.\" % (filename))\n",
    "                continue\n",
    "\n",
    "            # Move it.\n",
    "            dest = os.path.join(group, classname, filename)\n",
    "            print(\"Moving %s to %s\" % (filename, dest))\n",
    "            os.rename(filename, dest)\n",
    "\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Go through each of our train/test text files and move the videos\n",
    "to the right place.\n",
    "\"\"\"\n",
    "\n",
    "# Get the videos in groups so we can move them.\n",
    "group_lists = get_train_test_lists()\n",
    "\n",
    "# Move the files.\n",
    "move_files(group_lists)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# DONE - DO NOT RUN!\n",
    "# (adapted from:\n",
    "#   https://github.com/harvitronix/five-video-classification-methods/blob/master/data/2_extract_files.py )\n",
    "\n",
    "\"\"\"\n",
    "After moving all the files using the 1_ file, we run this one to extract\n",
    "the images from the videos and also create a data file we can use\n",
    "for training and testing later.\n",
    "\"\"\"\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import os.path\n",
    "from subprocess import call\n",
    "\n",
    "os.chdir(\"/home/adrian01/ucf101\")\n",
    "\n",
    "def extract_files():\n",
    "    \"\"\"After we have all of our videos split between train and test, and\n",
    "    all nested within folders representing their classes, we need to\n",
    "    make a data file that we can reference when training our RNN(s).\n",
    "    This will let us keep track of image sequences and other parts\n",
    "    of the training process.\n",
    "    We'll first need to extract images from each of the videos. We'll\n",
    "    need to record the following data in the file:\n",
    "    [train|test], class, filename, nb frames\n",
    "    Extracting can be done with ffmpeg:\n",
    "    `ffmpeg -i video.mpg image-%04d.jpg`\n",
    "    \"\"\"\n",
    "    \n",
    "    os.chdir(\"/home/adrian01/ucf101\")\n",
    "    \n",
    "    data_file = []\n",
    "    folders = ['train', 'test']\n",
    "\n",
    "    for folder in folders:\n",
    "        class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "\n",
    "        for vid_class in class_folders:\n",
    "            class_files = glob.glob(os.path.join(vid_class, '*.avi'))\n",
    "\n",
    "            for video_path in class_files:\n",
    "                # Get the parts of the file.\n",
    "                video_parts = get_video_parts(video_path)\n",
    "\n",
    "                train_or_test, classname, filename_no_ext, filename = video_parts\n",
    "\n",
    "                # Only extract if we haven't done it yet. Otherwise, just get\n",
    "                # the info.\n",
    "                if not check_already_extracted(video_parts):\n",
    "                    # Now extract it.\n",
    "                    src = os.path.join(train_or_test, classname, filename)\n",
    "                    dest = os.path.join(train_or_test, classname,\n",
    "                        filename_no_ext + '-%04d.jpg')\n",
    "                    call([\"ffmpeg\", \"-i\", src, dest])\n",
    "\n",
    "                # Now get how many frames it is.\n",
    "                nb_frames = get_nb_frames_for_video(video_parts)\n",
    "\n",
    "                data_file.append([train_or_test, classname, filename_no_ext, nb_frames])\n",
    "\n",
    "                print(\"Generated %d frames for %s\" % (nb_frames, filename_no_ext))\n",
    "\n",
    "    with open('data_file.csv', 'w') as fout:\n",
    "        writer = csv.writer(fout)\n",
    "        writer.writerows(data_file)\n",
    "\n",
    "    print(\"Extracted and wrote %d video files.\" % (len(data_file)))\n",
    "\n",
    "def get_nb_frames_for_video(video_parts):\n",
    "    \"\"\"Given video parts of an (assumed) already extracted video, return\n",
    "    the number of frames that were extracted.\"\"\"\n",
    "    \n",
    "    os.chdir(\"/home/adrian01/ucf101\")\n",
    "    \n",
    "    train_or_test, classname, filename_no_ext, _ = video_parts\n",
    "    generated_files = glob.glob(os.path.join(train_or_test, classname,\n",
    "                                filename_no_ext + '*.jpg'))\n",
    "    return len(generated_files)\n",
    "\n",
    "def get_video_parts(video_path):\n",
    "    \"\"\"Given a full path to a video, return its parts.\"\"\"\n",
    "    \n",
    "    os.chdir(\"/home/adrian01/ucf101\")\n",
    "    \n",
    "    parts = video_path.split(os.path.sep)\n",
    "    filename = parts[2]\n",
    "    filename_no_ext = filename.split('.')[0]\n",
    "    classname = parts[1]\n",
    "    train_or_test = parts[0]\n",
    "\n",
    "    return train_or_test, classname, filename_no_ext, filename\n",
    "\n",
    "def check_already_extracted(video_parts):\n",
    "    \"\"\"Check to see if we created the -0001 frame of this file.\"\"\"\n",
    "    \n",
    "    os.chdir(\"/home/adrian01/ucf101\")\n",
    "    \n",
    "    train_or_test, classname, filename_no_ext, _ = video_parts\n",
    "    return bool(os.path.exists(os.path.join(train_or_test, classname,\n",
    "                               filename_no_ext + '-0001.jpg')))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Extract images from videos and build a new file that we\n",
    "can use as our data input file. It can have format:\n",
    "[train|test], class, filename, nb frames\n",
    "\"\"\"\n",
    "\n",
    "# Should report extracting and writing from 13320 video files\n",
    "\n",
    "extract_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python_3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
