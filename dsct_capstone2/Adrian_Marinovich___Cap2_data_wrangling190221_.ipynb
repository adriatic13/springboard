{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adrian Marinovich\n",
    "# Springboard - Data Science Career Track \n",
    "# Capstone Project #2\n",
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "from subprocess import call\n",
    "\n",
    "from scipy.stats import reciprocal, uniform\n",
    "from scipy.misc import imsave\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# for reproducibility:\n",
    "np.random.seed(41)\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(51)\n",
    "random.seed(61)\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "    \n",
    "from keras.models import model_from_yaml\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.svm import SVC \n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# setup plots\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Adapted from:\n",
    "#    https://github.com/harvitronix/five-video-classification-methods\n",
    "#    https://github.com/wushidonguc/two-stream-action-recognition-keras )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain data\n",
    "#\n",
    "# bash command line in data folder:\n",
    "# $ wget http://crcv.ucf.edu/data/UCF101/UCF101.rar\n",
    "# $ unrar e UCF101.rar\n",
    "# $ mkdir train && mkdir test && mkdir sequences && mkdir checkpoints\n",
    "# \n",
    "# Get following 2 files from:\n",
    "#     https://github.com/harvitronix/five-video-classification-methods/tree/master/data/ucfTrainTestlist\n",
    "#\n",
    "#   trainlist01.txt\n",
    "#   testlist01.txt\n",
    "#\n",
    "#   ...and put in /home/adrian01/ucf101_lists\n",
    "#\n",
    "# Alternate train-test split lists can be obtained by downloading:\n",
    "#     http://crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-RecognitionTask.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#        ***** Only run this file once *****\n",
    "#\n",
    "# (adapted from:\n",
    "#   https://github.com/harvitronix/five-video-classification-methods/blob/master/data/1_move_files.py )\n",
    "\n",
    "# This moves all the files into appropriate train or test/validation directories,\n",
    "#   nested within subdirectories representing their classes\n",
    "#\n",
    "#        ***** Only run this file once *****\n",
    "#\n",
    "\n",
    "def get_train_test_lists(version='01'):\n",
    "    # Uses the train and test lists created by UCF team, downloaded above\n",
    "        \n",
    "    os.chdir(\"/home/adrian01/ucf101_lists\")\n",
    "\n",
    "    test_file = os.path.join('/home/adrian01/ucf_lists/testlist01.txt')\n",
    "    train_file = os.path.join('/home/adrian01/ucf_lists/trainlist01.txt')\n",
    "\n",
    "    os.chdir(\"/home/adrian01/ucf101\")\n",
    "    \n",
    "    # Build the test list\n",
    "    with open(test_file) as fin:\n",
    "        test_list = [row.strip() for row in list(fin)]\n",
    "\n",
    "    # Build the train list. Extra step to remove the class index.\n",
    "    with open(train_file) as fin:\n",
    "        train_list = [row.strip() for row in list(fin)]\n",
    "        train_list = [row.split(' ')[0] for row in train_list]\n",
    "\n",
    "    # Set the groups in a dictionary.\n",
    "    file_groups = {\n",
    "        'train': train_list,\n",
    "        'test': test_list\n",
    "    }\n",
    "\n",
    "    return file_groups\n",
    "\n",
    "def move_files(file_groups):\n",
    "    \n",
    "    os.chdir(\"/home/adrian01/ucf101\")\n",
    "    \n",
    "    # Do each of our groups.\n",
    "    for group, videos in file_groups.items():\n",
    "\n",
    "        # Do each of our videos.\n",
    "        for video in videos:\n",
    "\n",
    "            # Get the parts.\n",
    "            parts = video.split(os.path.sep)\n",
    "            classname = parts[0]\n",
    "            filename = parts[1]\n",
    "\n",
    "            # Check if this class exists.\n",
    "            if not os.path.exists(os.path.join(group, classname)):\n",
    "                print(\"Creating folder for %s/%s\" % (group, classname))\n",
    "                os.makedirs(os.path.join(group, classname))\n",
    "\n",
    "            # Check if we have already moved this file, or at least that it\n",
    "            # exists to move.\n",
    "            if not os.path.exists(filename):\n",
    "                print(\"Can't find %s to move. Skipping.\" % (filename))\n",
    "                continue\n",
    "\n",
    "            # Move it.\n",
    "            dest = os.path.join(group, classname, filename)\n",
    "            print(\"Moving %s to %s\" % (filename, dest))\n",
    "            os.rename(filename, dest)\n",
    "\n",
    "    print(\"Done.\")\n",
    "\n",
    "# Now do it:\n",
    "\n",
    "# Get the videos in groups so we can move them.\n",
    "group_lists = get_train_test_lists()\n",
    "\n",
    "# Move the files.\n",
    "move_files(group_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#        ***** Only run this file once *****\n",
    "#\n",
    "# (adapted from:\n",
    "#   https://github.com/harvitronix/five-video-classification-methods/blob/master/data/2_extract_files.py )\n",
    "\n",
    "# This extracts still images from the videos, and also \n",
    "#   creates a data_file.csv video metadata list used later.\n",
    "#\n",
    "#        ***** Only run this file once *****\n",
    "#\n",
    "\n",
    "os.chdir(\"/home/adrian01/ucf101\")\n",
    "\n",
    "def extract_files():\n",
    "    # The following data is in the image file name:\n",
    "    #   [train|test], class, filename, number of frames\n",
    "    # Extraction done with ffmpeg:\n",
    "    #   `ffmpeg -i video.mpg image-%04d.jpg`\n",
    "    \n",
    "    os.chdir(\"/home/adrian01/ucf101\")\n",
    "    \n",
    "    data_file = []\n",
    "    folders = ['train', 'test']\n",
    "\n",
    "    for folder in folders:\n",
    "        class_folders = glob.glob(os.path.join(folder, '*'))\n",
    "\n",
    "        for vid_class in class_folders:\n",
    "            class_files = glob.glob(os.path.join(vid_class, '*.avi'))\n",
    "\n",
    "            for video_path in class_files:\n",
    "                # Get the parts of the file.\n",
    "                video_parts = get_video_parts(video_path)\n",
    "\n",
    "                train_or_test, classname, filename_no_ext, filename = video_parts\n",
    "\n",
    "                # Only extract if we haven't done it yet. Otherwise, just get\n",
    "                # the info.\n",
    "                if not check_already_extracted(video_parts):\n",
    "                    # Now extract it.\n",
    "                    src = os.path.join(train_or_test, classname, filename)\n",
    "                    dest = os.path.join(train_or_test, classname,\n",
    "                        filename_no_ext + '-%04d.jpg')\n",
    "                    call([\"ffmpeg\", \"-i\", src, dest])\n",
    "\n",
    "                # Now get how many frames it is.\n",
    "                nb_frames = get_nb_frames_for_video(video_parts)\n",
    "\n",
    "                data_file.append([train_or_test, classname, filename_no_ext, nb_frames])\n",
    "\n",
    "                print(\"Generated %d frames for %s\" % (nb_frames, filename_no_ext))\n",
    "\n",
    "    with open('data_file.csv', 'w') as fout:\n",
    "        writer = csv.writer(fout)\n",
    "        writer.writerows(data_file)\n",
    "\n",
    "    print(\"Extracted and wrote %d video files.\" % (len(data_file)))\n",
    "\n",
    "def get_nb_frames_for_video(video_parts):\n",
    "    # For previously extracted video, return number of frames extracted\n",
    "    \n",
    "    os.chdir(\"/home/adrian01/ucf101\")\n",
    "    \n",
    "    train_or_test, classname, filename_no_ext, _ = video_parts\n",
    "    generated_files = glob.glob(os.path.join(train_or_test, classname,\n",
    "                                filename_no_ext + '*.jpg'))\n",
    "    return len(generated_files)\n",
    "\n",
    "def get_video_parts(video_path):\n",
    "    # Given a full path to a video, return its parts\n",
    "    \n",
    "    os.chdir(\"/home/adrian01/ucf101\")\n",
    "    \n",
    "    parts = video_path.split(os.path.sep)\n",
    "    filename = parts[2]\n",
    "    filename_no_ext = filename.split('.')[0]\n",
    "    classname = parts[1]\n",
    "    train_or_test = parts[0]\n",
    "\n",
    "    return train_or_test, classname, filename_no_ext, filename\n",
    "\n",
    "def check_already_extracted(video_parts):\n",
    "    # Check to see if we created the -0001 frame of this file\n",
    "    \n",
    "    os.chdir(\"/home/adrian01/ucf101\")\n",
    "    \n",
    "    train_or_test, classname, filename_no_ext, _ = video_parts\n",
    "    return bool(os.path.exists(os.path.join(train_or_test, classname,\n",
    "                               filename_no_ext + '-0001.jpg')))\n",
    "\n",
    "# Now do it:\n",
    "# Should report extracting and writing from 13320 video files\n",
    "extract_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
